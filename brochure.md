Big Data
	:1 Personalized Learning Hands on exercises, project work, quiz, capstone projects 24*7 Support For effective online Learning experience Innovative LMS For effective online Learning experience Peer Networking Learn trough Hackathons and Group Learning Gamified Learning Program Pedagogy Get trained by top industry experts Instructor led Training Learn at your own pace with world-class content Self-paced videos Get real-world experience through projects Projects and Exercises Get a sense of how real projects are built Hackathons Improve your professional network and learn from peers Peer Networking and Group Learning Get involved in group activities to solve real-world problems Gamified Learning Hands-on exercises, project work, quizzes, and capstone projects 1:1 Personalized Learning Program Pedagogy Page - 2 Program Curriculum Module 1 Module 5 Module 6 Module 7 Module 8 Hadoop Installation and Setup Advanced Hive and Impala Introduction to Pig Flume, Sqoop and HBase Writing Spark Applications Using Scala The architecture of Hadoop cluster What is High Availability and Federation? How to setup a production cluster? Various shell commands in Hadoop Understanding configuration files in Hadoop Installing a single node cluster with Cloudera Manager Understanding Spark, Scala, Sqoop, Pig, and Flume Indexing in Hive The ap Side Join in Hive Working with complex data types The Hive user-defined functions Introduction to Impala Comparing Hive with Impala The detailed architecture of Impala Indexing in Hive The ap Side Join in Hive Working with complex data types The Hive user-defined functions Introduction to Impala Comparing Hive with Impala The detailed architecture of Impala Apache Pig introduction and its various features Various data types and schema in Hive The available functions in Pig, Hive Bags, Tuples, and FieldApache Sqoop introduction Importing and exporting data Performance improvement with Sqoop Sqoop limitations Introduction to Flume and understanding the architecture of Flume What is HBase and the CAP theorem? Using Scala for writing Apache Spark applications Detailed study of Scala The need for Scala The concept of object-oriented programming Executing the Scala code Various classes in Scala like getters, setters, constructors, abstract, extending objects, overriding methods The Java and Scala interoperability The concept of functional programming and anonymous functions Bobsrockets package and comparing the mutable and immutable collections Scala REPL, Lazy Values, Control Structures in Scala, Directed Acyclic Graph (DAG), first Spark application using SBT/Eclipse, Spark Web UI, Spark in Hadoop ecosystem. Introducing Big Data and Hadoop What is Big Data and where does Hadoop fit in? Two important Hadoop ecosystem components, namely, MapReduce and HDFS In-depth Hadoop Distributed File System Replications, Block Size, Secondary Name node, High Availability and in-depth YARN resource manager and node manager Learning the working mechanism of MapReduce Understanding the mapping and reducing stages in MR Various terminologies in MR like Input Format, Output Format, Partitioners, Combiners, Shuffle, and Sort Introducing Hadoop Hive Detailed architecture of Hive Comparing Hive with Pig and RDBMS Working with Hive Query Language Creation of a database, table, group by and other clauses Various types of Hive tables, HCatalog Storing the Hive Results, Hive partitioning, and Buckets Introducing Hadoop Hive Detailed architecture of Hive Comparing Hive with Pig and RDBMS Working with Hive Query Language Creation of a database, table, group by and other clauses Various types of Hive tables, HCatalog Storing the Hive Results, Hive partitioning, and Buckets Module 2 Introduction to Big Data Hadoop and Understanding HDFS and MapReduce Module 3 Deep Dive in MapReduce Module 4 Introduction to Hive Page - 3 IND: +91 7022374614 US: 1-800 216-8930 sales@intellipaat.com www.intellipaat.com Page - 4 IND: +91 7022374614 US: 1-800-216-8930 sales@intellipaat.com www.intellipaat.com Program Curriculum Module 9 Use Case Bobsrockets Package Introduction to Scala packages and imports The selective imports The Scala test classes Introduction to JUnit test class JUnit interface via JUnit 3 suite for Scala test Packaging of Scala applications in the directory structure Examples of Spark Split and Spark Scala Module 13 Aggregating Data with Pair RDDs Understanding the concept of key-value pair in RDDs Learning how Spark makes MapReduce operations faster Various operations of RDD MapReduce interactive operations Fine and coarse-grained update Spark stack Module 14 Writing and Deploying Spark Applications Comparing the Spark applications with Spark Shell Creating a Spark application using Scala or Java Deploying a Spark application Scala built application Creation of the mutable list, set and set operations, list, tuple, and concatenating list Creating an application using SBT Deploying an application using Maven The web user interface of Spark application A real-world example of Spark Configuring of Spark Module 15 Project Solution Discussion Working towards the solution of the Hadoop project solution Its problem statements and the possible solution outcomes Preparing for the Cloudera certifications Points to focus on scoring the highest marks Tips for cracking Hadoop interview questions Module 16 Parallel Processing Learning about Spark parallel processing Deploying on a cluster Introduction to Spark partitions File-based partitioning of RDDs Understanding of HDFS and data locality Mastering the technique of parallel operations Comparing repartition and coalesce RDD actions Module 10 Module 11 Module 12 Introduction to Spark Spark Basics Working with RDDs in Spark Introduction to Spark Spark overcomes the drawbacks of working on MapReduce Understanding in-memory MapReduce Interactive operations on MapReduce Spark stack, fine vs. coarse-grained update, Spark stack, Spark Hadoop YARN, HDFS Revision, and YARN Revision The overview of Spark and how it is better than Hadoop Deploying Spark without Hadoop Spark history server and Cloudera distribution Spark installation guide Spark configuration Memory management Executor memory vs. driver memory Working with Spark Shell The concept of resilient distributed datasets (RDD) Learning to do functional programming in Spark The architecture of Spark Spark RDD Creating RDDs RDD partitioning Operations and transformation in RDD Deep dive into Spark RDDs The RDD general operations Read-only partitioned collection of records Using the concept of RDD for faster and efficient data processing RDD action for the collect, count, collects map, save-as-text-files, and pair RDD functions Page - 5 IND: +91 7022374614 US: 1-800-216-8930 sales@intellipaat.com www.intellipaat.com Program Curriculum Module 17 Spark RDD Persistence The execution flow in Spark Understanding the RDD persistence overview Spark execution flow, and Spark terminology Distribution shared memory vs. RDD RDD limitations Spark shell arguments Distributed persistence RDD lineage Key-value pair for sorting implicit conversions like CountByKey, ReduceByKey, SortByKey, and AggregateByKey Module 23 Scheduling/Partitioning Learning about the scheduling and partitioning in Spark Hash partition Range partition Scheduling within and around applications Static partitioning, dynamic sharing, and fair scheduling Map partition with index, the Zip, and GroupByKey Spark master high availability, standby masters with ZooKeeper, single-node recovery with the local file system and high order functions Module 21 Improving Spark Performance Introduction to various variables in Spark like shared variables and broadcast variables Learning about accumulators The common performance issues Troubleshooting the performance problems Module 22 Spark SQL and Data Frames Learning about Spark SQL The context of SQL in Spark for providing structured data processing JSON support in Spark SQL Working with XML data Parquet files Creating Hive context Writing data frame to Hive Reading JDBC files Understanding the data frames in Spark Creating Data Frames Manual inferring of schema Working with CSV files Reading JDBC tables Data frame to JDBC User-defined functions in Spark SQL Shared variables and accumulators Learning to query and transform data in data frames Data frame provides the benefit of both Spark RDD and Spark SQL Deploying Hive on Spark as the execution engine Module 18 Module 19 Module 20 Spark MLlib Integrating Apache Flume and Apache Kafka Spark Streaming Introduction to Machine Learning Types of Machine Learning Introduction to MLlib Various ML algorithms supported by MLlib Linear regression, logistic regression, decision tree, random forest, and K-means clustering techniques Why Kafka and what is Kafka? Kafka architecture Kafka workflow Configuring Kafka cluster Operations Kafka monitoring tools Integrating Apache Flume and Apache Kafka Introduction to Spark Streaming Features of Spark Streaming Spark Streaming workflow Initializing StreamingContext, discretized Streams (DStreams), input DStreams and Receivers Transformations on DStreams, output operations on DStreams, windowed operators and why it is useful Important windowed operators and stateful operators Page - 6 IND: +91 7022374614 US: 1-800-216-8930 sales@intellipaat.com www.intellipaat.com Program Curriculum Module 24 Hadoop Administration – Multi-node Cluster Setup Using Amazon EC2 Module 25 Hadoop Administration – Cluster Configuration Module 27 ETL Connectivity with Hadoop Ecosystem (Self-Paced) Module 26 Hadoop Administration – Maintenance, Monitoring and Troubleshooting Module 30 Framework Called MRUnit for Testing of MapReduce Programs Module 31 Unit Testing Module 28 Hadoop Application Testing Importance of testing Unit testing, Integration testing, Performance testing, Diagnostics, Nightly QA test, Benchmark and end-to-end tests, Functional testing, Release certification testing, Security testing, Scalability testing, Commissioning and Decommissioning of data nodes testing, Reliability testing, and Release testing Module 29 Roles & Responsibilities of Hadoop Testing Professional Understanding the Requirement Preparation of the Testing Estimation Test Cases, Test Data, Test Bed Creation, Test Execution, Defect Reporting, Defect Retest, Daily Status report delivery, Test completion, ETL testing at every stage (HDFS, Hive and HBase) while loading the input (logs, files, records, etc.) using Sqoop/Flume which includes but not limited to data verification, Reconciliation, User Authorization and Authentication testing (Groups, Users, Privileges, etc.), reporting defects to the development team or manager and driving them to closure Consolidating all the defects and create defect reports Validating new feature and issues in Core Hadoop Report defects to the development team or manager and driving them to closure Consolidate all the defects and create defect reports Responsible for creating a testing framework called MRUnit for testing of MapReduce programs Automation testing using the OOZIE Data validation using the query surge tool Introduction to various variables in Spark like shared variables and broadcast variables Learning about accumulators The common performance issues Troubleshooting the performance problems Overview of Hadoop configuration The importance of Hadoop configuration file The various parameters and values of configuration The HDFS parameters and MapReduce parameters Setting up the Hadoop environment The Include and Exclude configuration files The administration and maintenance of name node, data node directory structures, and files What is a File system image? Understanding Edit log Introduction to the checkpoint procedure, name node failure How to ensure the recovery procedure, Safe Mode, Metadata and Data backup, various potential problems and solutions, what to look for and how to add and remove nodes How ETL tools work in Big Data industry? Introduction to ETL and data warehousing Working with prominent use cases of Big Data in ETL industry End-to-end ETL PoC showing Big Data integration with ETL tool Following topics will be available only in self-paced mode: Page - 7 Program Curriculum Module 32 Test Execution Module 33 Test Plan Strategy and Writing Test Cases for Testing Hadoop Application Preview Test plan for HDFS upgrade Test automation and result Test, install and configure Skills to Master Spark Scala Sqoop Impala Pig Apache Flume Hive HCatalog AVRO Apache Kafka Scala REPL SBT/Eclipse Spark Streaming Page - 8 IND: +91 7022374614 US: 1-800-216-8930 sales@intellipaat.com www.intellipaat.com Course Projects Working with MapReduce, Hive, and Sqoop In this project, the learners import MySQL data with the help of Sqoop. As an important requirement of the project, the learners are required to query the same, by using Hive, and run the word count with the use of MapReduce. Hadoop YARN Project: End-to-End PoC The Hadoop YARN project lets the learners import daily incremental data in HDFS. The project allows the learners to use Sqoop commands to import this data and also work with end-to-end data transaction flow and HDFS data. Work on MovieLens Data For Finding the Top Movies This project involves writing a MapReduce program to analyze the MovieLens data. The project also involves creating a list of top 10 movies by using Apache Pig and Apache Hive for working with distributed datasets. Table Partitioning in Hive It improves query speed by using Hive data partitioning. It also helps in getting experience on manual Hive tables partition and deploying single SQL execution in dynamic partitioning and bucket data to break it into managable chunks. Connecting Pentaho with Hadoop Ecosystem Learning to deploy ETL for data analysis activities, getting a chance to configure Pentaho, and working with Hadoop distribution. The learners also get hands-on experience to load, transform, and extract data from the Hadoop cluster. Hadoop Testing Using MRUnit Work with MRUnit to test the Hadoop application in isolation without spinning a cluster. The learners are also required to successfully map and reduce the tests in an application, as an important requirement of the project. Hadoop Maintenance Through this project, the learners will grasp how to administer a Hadoop cluster to maintain and manage it. Work with the name node directory structure, audit logging, data node block scanner, Hadoop file formats, etc. Multi-node Cluster Setup Set up a Hadoop real-time cluster on Amazon EC2. Install and configure Hadoop. Run a Hadoop multinode by using a 4-node cluster on Amazon EC2 and deploy a MapReduce job on the Hadoop cluster. Java installed is a prerequisite. Hadoop Web Log Analytics Twitter Sentiment Analysis The Hadoop Web Log Analytics project requires the learners to successfully derive insights from web log data. Aggregate log data and implement Apache Flume for data transportation. Also process the data to generate analytics. Use and successfully apply Twitter sentiment analysis to find the reaction of people concerning the demonetization move in India by analyzing their tweets. The learners can also download the tweets and load them into Pig storage. Projects cover the following industries: Retail Social Media Supply Chain Entrepreneurship E-commerce Banking Healthcare Insurance Page - 9 IND: +91 7022374614 US: 1-800-216-8930 sales@intellipaat.com www.intellipaat.com Some of their current employers include 25% 6-9 years 15% 9-12 years 10% 12+ years 20% 0-3 years 27% 3-6 years 20% 27% 25% 15% 13% Work Experience Meet the Batch 50% Information Technology 17% - BPO/ KPO 6% - Others 10% - Consulting 5% - Healthcare 12% - BFSI Industries Our Learners Come From Meet the Batch 50% Information Technology 17% - BPO/ KPO 6% - Others 10% - Consulting 5% - Healthcare 12% - BFSI Industries Our Learners Come From Page - 10 IND: +91 70223746Rajesh Sahoo 4.6 4.5 4.38 Page - 11 IND: +91 7022374614 US: 1-800-216-8930 sales@intellipaat.com www.intellipaat.com About Intellipaat Intellipaat is one of the leading online training providers with more than 1.2 million learners in over 155 countries. We are on a mission to democratize education as we believe that everyone has the right to quality education. We create courses in collaboration with top universities and MNCs for employability like IIT Madras, University of Essex, University of Liverpool, IIT Roorkee, IIT Guwahati, E&ICT MNIT Jaipur, SPJIMR, IBM, Microsoft, etc. Our courses are delivered by SMEs & our pedagogy enables quick learning of difficult topics. 24/7 technical support & career services help learners to jump-start their careers. About IBM IBM is a leading innovator in the technology space. In this master’s course, top subject matter experts will share knowledge in the domain of Big Data Hadoop. Benefits of this collaboration for learners: Industry-recognized certification Industry-specific case studies and project work sales@intellipaat.com www.intellipaat.com INDIA AMR Tech Park 3, Ground Floor, Tower B, Hongasandra Village, Bommanahalli, Hosur Road, Bangalore, Karnataka 560068, India Phone No: +91-7022374614 UK Flat 16 Bluepoint Court, 203 Station Road, Harrow, Middlesex HA1 2TS, UK USA 1219 E. Hillsdale Blvd. Suite 205, Foster City, CA 94404 Phone No: 1-800-216-8930 Contact Us 1.2 Million Learners & 200+ corporates across 155+ countries upskilling on Intellipaat platform